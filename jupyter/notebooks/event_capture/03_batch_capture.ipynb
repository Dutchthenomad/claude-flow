{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Batch Event Capture\n",
    "\n",
    "Automated overnight capture for building the knowledge pipeline.\n",
    "\n",
    "**Features:**\n",
    "- Long-running capture (hours)\n",
    "- Progress monitoring\n",
    "- Auto-file rotation\n",
    "- RAG pipeline integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Add lib to path\n",
    "lib_path = Path.cwd().parent.parent / 'lib'\n",
    "if str(lib_path) not in sys.path:\n",
    "    sys.path.insert(0, str(lib_path))\n",
    "\n",
    "from cdp_notebook import CDPCapture, MockCDPCapture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture settings\n",
    "DURATION_HOURS = 8              # How long to capture\n",
    "UPDATE_INTERVAL = 60            # Progress update interval (seconds)\n",
    "USE_MOCK = False                # Use mock for testing\n",
    "\n",
    "# Output settings\n",
    "OUTPUT_DIR = Path.home() / 'rugs_recordings' / 'batch_captures'\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SESSION_ID = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "OUTPUT_FILE = OUTPUT_DIR / f'batch_{SESSION_ID}.jsonl'\n",
    "\n",
    "print(\"Batch Capture Configuration\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Duration: {DURATION_HOURS} hours\")\n",
    "print(f\"Output: {OUTPUT_FILE}\")\n",
    "print(f\"Update interval: {UPDATE_INTERVAL}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## 2. Connect and Start Recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize capture\n",
    "capture = MockCDPCapture() if USE_MOCK else CDPCapture()\n",
    "\n",
    "if capture.connect():\n",
    "    capture.start_recording(str(OUTPUT_FILE))\n",
    "    print(\"\\nCapture started. Run the next cell to monitor progress.\")\n",
    "else:\n",
    "    print(\"\\nConnection failed. Check Chrome CDP is running.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## 3. Monitor Progress\n",
    "\n",
    "Run this cell to monitor the batch capture. Interrupt the kernel (Kernel > Interrupt) to stop early."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "duration_seconds = DURATION_HOURS * 3600\n",
    "\n",
    "print(f\"Starting {DURATION_HOURS}-hour batch capture...\")\n",
    "print(\"Press STOP (square button) or Kernel > Interrupt to stop early.\")\n",
    "print()\n",
    "\n",
    "try:\n",
    "    while (time.time() - start_time) < duration_seconds:\n",
    "        elapsed = time.time() - start_time\n",
    "        elapsed_hours = elapsed / 3600\n",
    "        remaining = duration_seconds - elapsed\n",
    "        remaining_hours = remaining / 3600\n",
    "        \n",
    "        events_count = len(capture.events)\n",
    "        events_per_hour = events_count / elapsed_hours if elapsed_hours > 0 else 0\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        # Progress bar\n",
    "        pct = elapsed / duration_seconds * 100\n",
    "        bar_len = 40\n",
    "        filled = int(bar_len * elapsed / duration_seconds)\n",
    "        bar = '=' * filled + '-' * (bar_len - filled)\n",
    "        \n",
    "        print(\"BATCH CAPTURE IN PROGRESS\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"[{bar}] {pct:.1f}%\")\n",
    "        print()\n",
    "        print(f\"Elapsed:    {elapsed_hours:.2f}h / {DURATION_HOURS}h\")\n",
    "        print(f\"Remaining:  {remaining_hours:.2f}h\")\n",
    "        print(f\"Events:     {events_count:,}\")\n",
    "        print(f\"Rate:       {events_per_hour:,.0f} events/hour\")\n",
    "        print()\n",
    "        \n",
    "        # Event distribution\n",
    "        counts = capture.get_event_counts()\n",
    "        print(\"Event Distribution (top 5):\")\n",
    "        for name, count in list(counts.items())[:5]:\n",
    "            print(f\"  {name}: {count:,}\")\n",
    "        \n",
    "        print()\n",
    "        print(f\"Output: {OUTPUT_FILE}\")\n",
    "        \n",
    "        time.sleep(UPDATE_INTERVAL)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n\\nCapture interrupted by user.\")\n",
    "\n",
    "finally:\n",
    "    # Final stats\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\nCapture Complete!\")\n",
    "    print(f\"Duration: {elapsed/3600:.2f} hours\")\n",
    "    print(f\"Total events: {len(capture.events):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## 4. Stop Recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = capture.stop_recording()\n",
    "capture.disconnect()\n",
    "\n",
    "# Verify output\n",
    "if filepath and Path(filepath).exists():\n",
    "    size_mb = Path(filepath).stat().st_size / (1024 * 1024)\n",
    "    with open(filepath) as f:\n",
    "        line_count = sum(1 for _ in f)\n",
    "    \n",
    "    print(f\"\\nOutput Summary:\")\n",
    "    print(f\"  File: {filepath}\")\n",
    "    print(f\"  Size: {size_mb:.2f} MB\")\n",
    "    print(f\"  Events: {line_count:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## 5. Ingest to Knowledge Pipeline\n",
    "\n",
    "Feed captured events into the RAG pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if RAG pipeline is available\n",
    "RAG_PIPELINE = Path(os.environ.get('CLAUDE_FLOW_ROOT', '')) / 'rag-pipeline'\n",
    "\n",
    "if RAG_PIPELINE.exists():\n",
    "    print(\"RAG Pipeline available at:\")\n",
    "    print(f\"  {RAG_PIPELINE}\")\n",
    "    print()\n",
    "    print(\"To ingest captured events, run:\")\n",
    "    print(f\"\")\n",
    "    print(f\"  cd {RAG_PIPELINE}\")\n",
    "    print(f\"  source .venv/bin/activate\")\n",
    "    print(f\"  python -m ingestion.jsonl_ingest {OUTPUT_FILE}\")\n",
    "else:\n",
    "    print(\"RAG Pipeline not found.\")\n",
    "    print(\"Set CLAUDE_FLOW_ROOT environment variable.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Run ingestion from notebook\n",
    "RUN_INGESTION = False  # Set True to run\n",
    "\n",
    "if RUN_INGESTION and RAG_PIPELINE.exists():\n",
    "    import subprocess\n",
    "    \n",
    "    print(\"Running RAG ingestion...\")\n",
    "    result = subprocess.run(\n",
    "        ['python', '-m', 'ingestion.jsonl_ingest', str(OUTPUT_FILE)],\n",
    "        cwd=str(RAG_PIPELINE),\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"Ingestion complete!\")\n",
    "        print(result.stdout)\n",
    "    else:\n",
    "        print(\"Ingestion failed:\")\n",
    "        print(result.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Batch Capture History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List previous batch captures\n",
    "import pandas as pd\n",
    "\n",
    "captures = list(OUTPUT_DIR.glob('batch_*.jsonl'))\n",
    "captures.sort(key=lambda x: x.stat().st_mtime, reverse=True)\n",
    "\n",
    "if captures:\n",
    "    data = []\n",
    "    for f in captures[:10]:\n",
    "        size_mb = f.stat().st_size / (1024 * 1024)\n",
    "        with open(f) as fp:\n",
    "            lines = sum(1 for _ in fp)\n",
    "        data.append({\n",
    "            'file': f.name,\n",
    "            'size_mb': f\"{size_mb:.1f}\",\n",
    "            'events': f\"{lines:,}\"\n",
    "        })\n",
    "    \n",
    "    print(f\"Recent batch captures ({OUTPUT_DIR}):\")\n",
    "    display(pd.DataFrame(data))\n",
    "else:\n",
    "    print(\"No batch captures found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
