{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Coverage Dashboard\n",
    "\n",
    "Visualize documentation coverage and identify gaps in the knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from _paths import *\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 1. Tier Distribution\n",
    "\n",
    "How many events are at each verification tier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "schemas = load_discovered_schemas()\n",
    "\n",
    "# Count by tier\n",
    "tier_counts = {'THEORETICAL': 0, 'OBSERVED': 0, 'VERIFIED': 0, 'CANONICAL': 0}\n",
    "for schema in schemas.values():\n",
    "    tier = schema.get('tier', 'OBSERVED')\n",
    "    tier_counts[tier] = tier_counts.get(tier, 0) + 1\n",
    "\n",
    "# Create bar chart\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "tiers = list(tier_counts.keys())\n",
    "counts = list(tier_counts.values())\n",
    "colors = ['#ff6b6b', '#ffd93d', '#6bcf7a', '#4dabf7']\n",
    "\n",
    "bars = ax.bar(tiers, counts, color=colors)\n",
    "ax.set_ylabel('Number of Events')\n",
    "ax.set_title('Event Distribution by Verification Tier')\n",
    "\n",
    "# Add count labels\n",
    "for bar, count in zip(bars, counts):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
    "            str(count), ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary stats\n",
    "total = sum(counts)\n",
    "canonical_pct = tier_counts['CANONICAL'] / total * 100 if total > 0 else 0\n",
    "print(f\"\\nTotal Events: {total}\")\n",
    "print(f\"CANONICAL Coverage: {canonical_pct:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## 2. Field Coverage by Event\n",
    "\n",
    "Which events have the most/least documented fields?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe of events\n",
    "event_data = []\n",
    "for event_name, schema in schemas.items():\n",
    "    fields = schema.get('fields', {})\n",
    "    documented = sum(1 for f in fields.values() if f.get('description'))\n",
    "    event_data.append({\n",
    "        'event': event_name,\n",
    "        'tier': schema.get('tier', 'OBSERVED'),\n",
    "        'total_fields': len(fields),\n",
    "        'documented_fields': documented,\n",
    "        'samples': schema.get('sample_count', 0)\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(event_data)\n",
    "if not df.empty:\n",
    "    df['coverage_pct'] = (df['documented_fields'] / df['total_fields'] * 100).fillna(0)\n",
    "    df = df.sort_values('total_fields', ascending=False)\n",
    "    \n",
    "    print(\"Top 15 Events by Field Count:\")\n",
    "    display(df.head(15)[['event', 'tier', 'total_fields', 'documented_fields', 'coverage_pct', 'samples']])\n",
    "else:\n",
    "    print(\"No event data available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## 3. Sample Distribution\n",
    "\n",
    "Which events have the most observations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    # Top events by sample count\n",
    "    top_sampled = df.nlargest(15, 'samples')\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    bars = ax.barh(top_sampled['event'], top_sampled['samples'], color='steelblue')\n",
    "    ax.set_xlabel('Sample Count')\n",
    "    ax.set_title('Top 15 Events by Sample Count')\n",
    "    ax.invert_yaxis()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nTotal samples across all events: {df['samples'].sum():,}\")\n",
    "    print(f\"Median samples per event: {df['samples'].median():.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## 4. ChromaDB Collection Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    client = get_chromadb_client()\n",
    "    collections = client.list_collections()\n",
    "    \n",
    "    print(\"ChromaDB Collections:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    collection_data = []\n",
    "    for coll in collections:\n",
    "        count = coll.count()\n",
    "        collection_data.append({\n",
    "            'collection': coll.name,\n",
    "            'documents': count\n",
    "        })\n",
    "        print(f\"  {coll.name}: {count:,} documents\")\n",
    "    \n",
    "    if collection_data:\n",
    "        fig, ax = plt.subplots(figsize=(8, 4))\n",
    "        coll_df = pd.DataFrame(collection_data)\n",
    "        ax.bar(coll_df['collection'], coll_df['documents'], color='coral')\n",
    "        ax.set_ylabel('Documents')\n",
    "        ax.set_title('Documents per Collection')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ChromaDB not available: {e}\")\n",
    "    print(\"Run: cd rag-pipeline && python -m ingestion.ingest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## 5. Documentation Gaps\n",
    "\n",
    "Events with high sample counts but not yet CANONICAL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    # High-sample events not yet canonical\n",
    "    gaps = df[(df['samples'] > 100) & (df['tier'] != 'CANONICAL')]\n",
    "    gaps = gaps.sort_values('samples', ascending=False)\n",
    "    \n",
    "    print(f\"Events with 100+ samples not yet CANONICAL: {len(gaps)}\\n\")\n",
    "    \n",
    "    if not gaps.empty:\n",
    "        print(\"Priority candidates for promotion:\")\n",
    "        display(gaps.head(10)[['event', 'tier', 'samples', 'total_fields']])\n",
    "    else:\n",
    "        print(\"All high-sample events are CANONICAL!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## 6. Field Type Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = load_discovered_fields()\n",
    "\n",
    "# Count field types\n",
    "type_counts = {}\n",
    "for field_info in fields.values():\n",
    "    field_type = field_info.get('type', 'unknown')\n",
    "    type_counts[field_type] = type_counts.get(field_type, 0) + 1\n",
    "\n",
    "if type_counts:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    \n",
    "    # Sort and limit to top types\n",
    "    sorted_types = sorted(type_counts.items(), key=lambda x: -x[1])\n",
    "    labels = [t[0] for t in sorted_types[:8]]\n",
    "    sizes = [t[1] for t in sorted_types[:8]]\n",
    "    \n",
    "    # Add 'other' category\n",
    "    other_count = sum(t[1] for t in sorted_types[8:])\n",
    "    if other_count > 0:\n",
    "        labels.append('other')\n",
    "        sizes.append(other_count)\n",
    "    \n",
    "    ax.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)\n",
    "    ax.set_title('Field Type Distribution')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nTotal field paths: {len(fields)}\")\n",
    "    print(f\"Unique types: {len(type_counts)}\")\n",
    "else:\n",
    "    print(\"No field data available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## 7. Coverage Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary report\n",
    "print(\"KNOWLEDGE BASE COVERAGE REPORT\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M')}\")\n",
    "print()\n",
    "\n",
    "print(\"Events:\")\n",
    "for tier, count in tier_counts.items():\n",
    "    pct = count / sum(tier_counts.values()) * 100 if sum(tier_counts.values()) > 0 else 0\n",
    "    print(f\"  {tier}: {count} ({pct:.1f}%)\")\n",
    "\n",
    "print(f\"\\nFields:\")\n",
    "print(f\"  Total paths: {len(fields)}\")\n",
    "print(f\"  Unique types: {len(type_counts) if type_counts else 0}\")\n",
    "\n",
    "if not df.empty:\n",
    "    print(f\"\\nSamples:\")\n",
    "    print(f\"  Total: {df['samples'].sum():,}\")\n",
    "    print(f\"  Median per event: {df['samples'].median():.0f}\")\n",
    "\n",
    "print(f\"\\nPromotion Queue:\")\n",
    "verified_count = tier_counts.get('VERIFIED', 0)\n",
    "print(f\"  VERIFIED (pending human approval): {verified_count}\")\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- **02_canonical_review.ipynb** - Approve pending promotions\n",
    "- **04_rl_bot_analysis.ipynb** - Analyze RL model performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
